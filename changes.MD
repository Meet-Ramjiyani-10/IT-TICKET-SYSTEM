# UCL

UCL DATA
|
â”œâ”€â”€ EDA (understand distributions & labels)
|
â”œâ”€â”€ Text Processing (shared)
|
â”œâ”€â”€ â”€â”€â–º Classification (category / type)
|
â”œâ”€â”€ â”€â”€â–º Priority Prediction
|
â”œâ”€â”€ â”€â”€â–º Handle Time Prediction (regression)
|
â””â”€â”€ â”€â”€â–º Incident Clustering (unsupervised)

project/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ ucl_incidents.csv
â”‚   â””â”€â”€ processed/
â”‚       â””â”€â”€ ucl_master_df.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_ucl_eda.ipynb
â”‚   â”œâ”€â”€ 02_text_features.ipynb
â”‚   â”œâ”€â”€ 03_classification.ipynb
â”‚   â”œâ”€â”€ 04_priority_prediction.ipynb
â”‚   â”œâ”€â”€ 05_handle_time_regression.ipynb
â”‚   â””â”€â”€ 06_incident_clustering.ipynb
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ [EDA.md](http://eda.md/)
â”‚   â””â”€â”€ MODELING_NOTES.md
â”‚
â””â”€â”€ [README.md](http://readme.md/)

### ğŸ†” Identity / Metadata

- `number` â†’ incident ID
- `sys_created_at`, `sys_updated_at` â†’ system metadata (mostly useless)

### ğŸ•’ Time

- `opened_at` â†’ **incident creation time**
- `resolved_at` â†’ when issue was resolved
- `closed_at` â†’ final closure

ğŸ‘‰ These allow **time-to-resolution** and **SLA modeling**

---

### ğŸ“Œ Labels / Business Fields

- `category`, `subcategory` â†’ incident type
- `impact` â†’ business impact
- `urgency` â†’ how fast it must be handled
- `priority` â†’ assigned importance
- `incident_state` â†’ lifecycle state

---

### ğŸ“Š Operational Signals

- `reassignment_count` â†’ handoffs (very important)
- `reopen_count` â†’ quality issues
- `assignment_group`, `assigned_to` â†’ workload (high-cardinality)
- `made_sla` â†’ **SLA met or not** (THIS IS GOLD)

---

### ğŸ“ Text

- `u_symptom` â†’ short free text symptom description

This is **limited but usable**.

This dataset is called:

> Incident Management Process â€“ Enriched Event Log
> 

That phrase matters.

### What that means

Each **incident (`number`) appears multiple times**, once per **state change**:

Example you showed:

```
INC0000045 â†’New
INC0000045 â†’ Resolved
INC0000045 â†’ Resolved
INC0000045 â†’ Closed

```

So this dataset is **NOT**:

- one row = one incident âŒ

It **IS**:

- one row = one **event in the lifecycle** of an incident âœ…

> event-level data â†’ incident-level data
> 

### Rule (LOCK THIS)

For each `number` (incident):

- `opened_at` â†’ earliest
- `resolved_at` â†’ last resolved
- `closed_at` â†’ last closed
- `made_sla` â†’ final value
- `reassignment_count` â†’ max
- `reopen_count` â†’ max
- `sys_mod_count` â†’ max
- categorical fields â†’ **first or mode**

## WHAT WE DO ABOUT ZERO-TIME INCIDENTS (ENGINEERING DECISION)

### âŒ Wrong approach

- Drop them silently
- Pretend they donâ€™t exist

### âœ… Correct approach

- Keep them for SLA classification
- **Exclude them from handle-time regression**
- Document this decision

We will do this later â€” just be aware now.

1-02-2006 (information )

## Dataset Selection (UCL / UCI Incident Management Dataset)

We selected the **UCL / UCI Incident Management Process â€“ Enriched Event Log** dataset.

### Why this dataset?

- Real **ITSM-style incident data**
- Contains:
    - impact, urgency, priority
    - SLA outcome (`made_sla`)
    - timestamps (`opened_at`, `resolved_at`, `closed_at`)
- Suitable for **SLA risk, time prediction, and clustering**
- Clean dataset (no missing values)

âš ï¸ Important detail:

- This dataset is an **event log**, not a simple table
- Each incident appears **multiple times** (one row per lifecycle event)

---

## 2ï¸âƒ£ Event-Level â†’ Incident-Level Conversion (Very Important)

Before any ML, we **converted the event log into an incident-level dataset**.

### What we did:

- Grouped rows by `incident number`
- Aggregated lifecycle information:
    - `opened_at` â†’ earliest
    - `resolved_at` / `closed_at` â†’ latest
    - `made_sla` â†’ final outcome
    - counts â†’ max values
    - category / priority â†’ first value

### Result:

- **One row = one incident**
- ~25,000 unique incidents
- This prevents **data leakage** and incorrect modeling

This step is critical and often done wrong â€” we did it correctly.

---

## 3ï¸âƒ£ Targeted EDA (Not Random Exploration)

We performed **decision-driven EDA**, not exploratory chaos.

### Questions we answered:

- Is SLA breach predictable at ticket creation time?
- Do operational features influence SLA outcomes?

### Findings:

- SLA is moderately imbalanced (~63% met / ~37% breached)
- SLA breach rates vary by:
    - priority
    - impact
    - urgency
    - category

### Conclusion:

- **SLA breach prediction is a valid ML problem**
- No post-resolution features are required

---

## 4ï¸âƒ£ Text Feature Feasibility Check (`u_symptom`)

We **did NOT jump into NLP immediately**.

### What we checked:

- Text length distribution
- Repeated symptom templates
- Basic token frequency

### Conclusion:

- Text is present but shallow
- Structured features are stronger for SLA
- Text can be added later as an improvement (v2)

This avoided unnecessary complexity.

---

## 5ï¸âƒ£ SLA Breach Baseline Model (Core ML Output)

### What we built:

- **Binary classification model**
- Target: `SLA breached` (not SLA met)
- Model: Logistic Regression
- Inputs:
    - priority
    - impact
    - urgency
    - category
    - subcategory
    - time features from `opened_at`

### Key points:

- No leakage (no resolution-time data)
- Model is interpretable and deployable

---

## 6ï¸âƒ£ Threshold Tuning (Business Decision)

Instead of using the default 0.5 threshold, we tuned it.

### Final choice:

- **Threshold = 0.4**

### Why?

- SLA breach recall â‰ˆ **83%**
- Missing breaches is more costly than false alarms
- This aligns with real operational risk systems

### Output:

- Model returns:
    - breach probability
    - risk flag (based on threshold)

---

## 7ï¸âƒ£ Model Saving & Documentation

We:

- Saved the **full ML pipeline** (preprocessing + model)
- Saved threshold configuration separately
- Documented:
    - what metrics matter (recall > accuracy)
    - why the model behaves this way
    - API input/output contract

This allows backend and frontend teams to work independently.

---

## 8ï¸âƒ£ What This Enables for the Team

Because of todayâ€™s work:

- Backend can expose `/predict/sla`
- Frontend can build SLA risk UI
- DevOps can containerize and deploy
- ML work is **no longer a blocker**

---

## 9ï¸âƒ£ Whatâ€™s Next (Planned ML Work)

### v2 ML Features (In Progress / Future):

- **Handle-time prediction (regression)**
- **Incident clustering (unsupervised)**
- Optional: add text features to SLA model

These are **enhancements**, not blockers.

## What We Did Before UCL

- Started with a generic support-ticket dataset
- Designed full system architecture and ML scope
- Built a master ticket schema
- Tried category & priority models
- Discovered **priority/category were deterministic** (rule-based, fake ML accuracy)
- Learned where **ML does NOT add value**

---

## ğŸ”¹ Why We Switched to UCL

- Needed data with **real uncertainty**
- UCL dataset is **ITSM event-log based**
- Contains lifecycle timestamps + SLA outcome
- Better suited for **SLA, time prediction, clustering**

---

## ğŸ”¹ What We Did With UCL (Today)

- Converted event-log â†’ **incident-level dataset**
- Performed targeted EDA (validated SLA predictability)
- Checked text feasibility (kept for later)
- Built **SLA breach baseline model**
- Tuned threshold (0.4) for high breach recall (~83%)
- Saved model + documented API contract

---

## ğŸ”¹ Current Status

- SLA ML baseline **DONE & pushed**
- Backend / Frontend / DevOps **unblocked**

---

## ğŸ”¹ Whatâ€™s Next

- Handle-time prediction (regression)
- Incident clustering (unsupervised)
- Optional text enhancement (v2)